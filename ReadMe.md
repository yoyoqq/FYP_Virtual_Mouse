# ğŸ¯ Virtual Mouse â€“ Final Year Project  

A real-time **hand gesture recognition system** that replaces the physical mouse with computer vision and machine learning. The project enables smooth cursor movement, clicks, and control through hand gestures, aiming to improve accessibility and humanâ€“computer interaction (HCI).  

## ğŸš€ Features  
- ğŸ‘‹ **Hand Tracking** â€“ Uses computer vision to detect and track hand landmarks in real time.  
- ğŸ–±ï¸ **Gesture Recognition** â€“ Neural networkâ€“based classifier for mouse actions (click, scroll, drag).  
- âš¡ **Low Latency** â€“ Optimized models reduce tracking latency to **< 5 ms**.  
- ğŸ¨ **Lightweight UI** â€“ Tkinter-based interface for demonstration and interaction.  
- ğŸ† **Recognition** â€“ Awarded *Best Innovation in Applied ML & HCI* at the **University of Greenwich Digital Shark Expo**.  

## ğŸ› ï¸ Tech Stack  
- **Languages**: Python  
- **Libraries/Frameworks**: OpenCV, TensorFlow/Keras, MediaPipe, scikit-learn  
- **UI**: Tkinter  
- **Paradigms**: OOP design for modularity and extensibility  

## ğŸ“‚ Project Structure  
```bash
FYP_Virtual_Mouse/
â”‚â”€â”€ dataset/          # Collected hand gesture data  
â”‚â”€â”€ models/           # Trained ML/DL models  
â”‚â”€â”€ src/              # Main source code (gesture tracking, recognition, mouse control)  
â”‚â”€â”€ ui/               # Tkinter-based demo UI  
â”‚â”€â”€ utils/            # Helper functions  
â”‚â”€â”€ requirements.txt  # Dependencies  
â”‚â”€â”€ README.md         # Project documentation  


## âš™ï¸ Installation & Usage
git clone https://github.com/yoyoqq/FYP_Virtual_Mouse.git
cd FYP_Virtual_Mouse
pip install -r requirements.txt
python src/main.py



## ğŸ“Š Results
Gesture Recognition Accuracy: 97%
Latency: Reduced to under 5 ms
Expo: Showcased as a Top 5% Project in the University of Greenwich Expo

ğŸ”— Links
Link: https://www.gre.ac.uk/digital-shark-expo/web-and-mobile-applications/yangan-yagol-xu-chen
